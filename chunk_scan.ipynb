{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a92542-4059-439b-994c-5cb97620ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32cd660d-bbc9-449c-a87d-903681560907",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleChunkScan(nn.Module):\n",
    "    def __init__(self, chunk_size, nheads, headdim, dstate):\n",
    "        super(SimpleChunkScan, self).__init__()\n",
    "        self.chunk_size = chunk_size\n",
    "        self.nheads = nheads\n",
    "        self.headdim = headdim\n",
    "        self.dstate = dstate\n",
    "\n",
    "    def forward(self, x, dt, A, B, C, D=None, z=None, dt_bias=None, initial_states=None):\n",
    "        batch, seqlen, nheads, headdim = x.shape\n",
    "        nchunks = (seqlen + self.chunk_size - 1) // self.chunk_size\n",
    "\n",
    "        # Initialize states and outputs\n",
    "        states = torch.zeros(batch, nheads, nchunks, headdim, self.dstate, device=x.device, dtype=x.dtype)\n",
    "        out = torch.zeros_like(x)\n",
    "        \n",
    "        # Perform chunked scan\n",
    "        for chunk in range(nchunks):\n",
    "            start_idx = chunk * self.chunk_size\n",
    "            end_idx = min((chunk + 1) * self.chunk_size, seqlen)\n",
    "            chunk_len = end_idx - start_idx\n",
    "\n",
    "            x_chunk = x[:, start_idx:end_idx, :, :]\n",
    "            dt_chunk = dt[:, start_idx:end_idx, :]\n",
    "            B_chunk = B[:, start_idx:end_idx, :, :]\n",
    "            C_chunk = C[:, start_idx:end_idx, :, :]\n",
    "            \n",
    "            if D is not None:\n",
    "                D_chunk = D[:, :]\n",
    "            else:\n",
    "                D_chunk = None\n",
    "\n",
    "            if dt_bias is not None:\n",
    "                dt_chunk += dt_bias.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "            if initial_states is not None and chunk == 0:\n",
    "                state = initial_states\n",
    "            else:\n",
    "                state = states[:, :, chunk - 1, :, :]\n",
    "\n",
    "            for t in range(chunk_len):\n",
    "                # Compute new state\n",
    "                dt_t = torch.exp(dt_chunk[:, t, :])\n",
    "                A_t = A.unsqueeze(0).unsqueeze(0)\n",
    "                B_t = B_chunk[:, t, :, :]\n",
    "                C_t = C_chunk[:, t, :, :]\n",
    "                \n",
    "                state = state * torch.exp(-dt_t.unsqueeze(-1)) + B_t\n",
    "\n",
    "                # Compute output\n",
    "                out[:, start_idx + t, :, :] = x_chunk[:, t, :, :] * (A_t + C_t)\n",
    "\n",
    "                if D_chunk is not None:\n",
    "                    out[:, start_idx + t, :, :] += x_chunk[:, t, :, :] * D_chunk\n",
    "\n",
    "                states[:, :, chunk, :, :] = state\n",
    "\n",
    "                if z is not None:\n",
    "                    out[:, start_idx + t, :, :] += z[:, start_idx + t, :, :]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33567f8-efd9-4fcd-894f-22d4053b5fc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (4) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m dt_bias \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(nheads)\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m SimpleChunkScan(chunk_size, nheads, headdim, dstate)\n\u001b[0;32m---> 19\u001b[0m out \u001b[38;5;241m=\u001b[39m model(x, dt, A, B, C, D, z, dt_bias)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 48\u001b[0m, in \u001b[0;36mSimpleChunkScan.forward\u001b[0;34m(self, x, dt, A, B, C, D, z, dt_bias, initial_states)\u001b[0m\n\u001b[1;32m     45\u001b[0m B_t \u001b[38;5;241m=\u001b[39m B_chunk[:, t, :, :]\n\u001b[1;32m     46\u001b[0m C_t \u001b[38;5;241m=\u001b[39m C_chunk[:, t, :, :]\n\u001b[0;32m---> 48\u001b[0m state \u001b[38;5;241m=\u001b[39m state \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mdt_t\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m B_t\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Compute output\u001b[39;00m\n\u001b[1;32m     51\u001b[0m out[:, start_idx \u001b[38;5;241m+\u001b[39m t, :, :] \u001b[38;5;241m=\u001b[39m x_chunk[:, t, :, :] \u001b[38;5;241m*\u001b[39m (A_t \u001b[38;5;241m+\u001b[39m C_t)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (4) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "nheads = 4\n",
    "headdim = 8\n",
    "dstate = 16\n",
    "chunk_size = 5\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, nheads, headdim)\n",
    "dt = torch.randn(batch_size, seq_len, nheads)\n",
    "A = torch.randn(nheads)\n",
    "B = torch.randn(batch_size, seq_len, nheads, dstate)\n",
    "C = torch.randn(batch_size, seq_len, nheads, dstate)\n",
    "D = torch.randn(nheads, headdim)\n",
    "z = torch.randn(batch_size, seq_len, nheads, headdim)\n",
    "dt_bias = torch.randn(nheads)\n",
    "\n",
    "model = SimpleChunkScan(chunk_size, nheads, headdim, dstate)\n",
    "out = model(x, dt, A, B, C, D, z, dt_bias)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daad331-ac6c-4cbe-954d-ddd13a339cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
